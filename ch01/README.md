# 1장. 신경망 복습

## 수학

- 벡터(2차원)와 행렬(3차원)
- 벡터의 내적(`np.dot`)과 행렬의 곱(`np.matmul`)

## 신경망의 추론 (순전파)

- 함수로서의 접근
- 완전연결계층
- 1개의 값에 대한 신경망의 추론
- 미니배치에 대한 신경망의 추론
- 완전연결계층에 의한 변환은 '선형'변환
- 활성화 함수를 통한 '비선형'효과 부여 - 신경망의 표현력 UP
  - Sigmoid 함수

- 구현 규칙
  - 모든 계층은 `forward()`와 `backward()` 메서드를 가진다.
  - 모든 계층은 인스턴스 변수인 `params`와 `grads`를 가진다.
  
## 신경망의 학습

- 손실함수
  - 교차 엔트로피 오차
  - 신경망의 출력으로 나오는 각 클래스별 확률과 정답 레이블로 구함
- Softmax 계층으로 확률값으로 변환
- Cross Entropy Error 계층으로 오차 구함
- 역전파
  - 계산그래프
    - 덧셈 노드 - 역전파시 값을 흘려보낸다.
    - 곱셈 노드 - 역전파시 기울기 X 순전파 시의 입력을 서로 바꾼 값
    - 분기 노드 - 역전파시 출력쪽에서 온 기울기들의 합
    - Repeat 노드 - 역전파시 출력쪽에서 온 기울기들의 합 (N개 분기 노드)
    - Sum 노드 - 역전파시 연결된 모든 화살표에 기울기를 분배
    - MatMul 노드 - 역전파시 